{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of COlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O dtrb.zip -q https://github.com/lohzhunyewcs/deep-text-recognition-benchmark/archive/refs/heads/transformer.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q dtrb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/deep-text-recognition-benchmark-transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir deep-text-recognition-benchmark-master/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data_lmdb_release.zip https://www.dropbox.com/sh/i39abvnefllx2si/AABX4yjNn2iLeKZh1OAwJUffa/data_lmdb_release.zip?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data_lmdb_release.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv data_lmdb_release deep-text-recognition-benchmark-transformer/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd deep-text-recognition-benchmark-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "--train_data data/training --valid_data data/validation \\\n",
    "--select_data MJ-ST --batch_ratio 0.5-0.5 \\\n",
    "--total_data_usage_ratio 0.001 \\\n",
    "--valInterval 1 \\\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction TransformerDecoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_model\n",
    "from global_args import get_cfgs\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input parameters 32 100 20 1 512 256 38 100 TPS ResNet BiLSTM TransformerDecoder\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (Transformation): TPS_SpatialTransformerNetwork(\n",
      "      (LocalizationNetwork): LocalizationNetwork(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU(inplace=True)\n",
      "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): ReLU(inplace=True)\n",
      "          (15): AdaptiveAvgPool2d(output_size=1)\n",
      "        )\n",
      "        (localization_fc1): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "      )\n",
      "      (GridGenerator): GridGenerator()\n",
      "    )\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): TransformerDecoder(\n",
      "      (position_embeddings): PositionalEmbedding(\n",
      "        (embeddings): Embedding(102, 256)\n",
      "      )\n",
      "      (word_embeddings): Embedding(102, 256)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerDecoderLayer(\n",
      "          (attention_1): AddNorm(\n",
      "            (sublayer): MultiHeadAttention(\n",
      "              (heads): ModuleList(\n",
      "                (0-7): 8 x AttentionHead(\n",
      "                  (q): Linear(in_features=256, out_features=32, bias=True)\n",
      "                  (k): Linear(in_features=256, out_features=32, bias=True)\n",
      "                  (v): Linear(in_features=256, out_features=32, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (attention_2): AddNorm(\n",
      "            (sublayer): MultiHeadAttention(\n",
      "              (heads): ModuleList(\n",
      "                (0-7): 8 x AttentionHead(\n",
      "                  (q): Linear(in_features=256, out_features=32, bias=True)\n",
      "                  (k): Linear(in_features=256, out_features=32, bias=True)\n",
      "                  (v): Linear(in_features=256, out_features=32, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): AddNorm(\n",
      "            (sublayer): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "            )\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(in_features=256, out_features=38, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "args = [\"--Transformation\", \"TPS\", \"--FeatureExtraction\", \"ResNet\", \"--SequenceModeling\", \"BiLSTM\", \"--Prediction\", \"TransformerDecoder\"]\n",
    "opt = get_cfgs(args)\n",
    "model, converter = load_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (position_embeddings): PositionalEmbedding(\n",
       "    (embeddings): Embedding(102, 256)\n",
       "  )\n",
       "  (word_embeddings): Embedding(102, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerDecoderLayer(\n",
       "      (attention_1): AddNorm(\n",
       "        (sublayer): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-7): 8 x AttentionHead(\n",
       "              (q): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (k): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (v): Linear(in_features=256, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (attention_2): AddNorm(\n",
       "        (sublayer): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-7): 8 x AttentionHead(\n",
       "              (q): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (k): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (v): Linear(in_features=256, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): AddNorm(\n",
       "        (sublayer): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text.shape = torch.Size([1, 102])\n"
     ]
    }
   ],
   "source": [
    "torch_inp = torch.rand(1, 1, 32, 100)\n",
    "# text= torch.Tensor([1,2,3,4]).unsqueeze(0).long()\n",
    "text, length = converter.encode([\"abc\"], batch_max_length=opt.batch_max_length)\n",
    "print(f'{text.shape = }')\n",
    "text = text[:, :-1]\n",
    "output = model(torch_inp, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 101, 38])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch_inp, text[:15]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[0] for _ in range(5)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> torch.Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninety = torch.tril(torch.ones(5, 5))\n",
    "ninety[ninety == 0] = -float('inf')\n",
    "ninety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((5,5)) * ninety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(5, 5) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (torch.triu(torch.ones(5, 5) * float('-inf'), diagonal=1) == 0).int()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_mask = ( torch.ones(5,5)  * float('-inf') ).masked_fill(mask=mask == 1, value=1)\n",
    "inf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5 ,5) * inf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ZY\\Desktop\\github_repos\\lohzhunyewcs\\deep-text-recognition-benchmark\\train.py\", line 16, in <module>\n",
      "    from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
      "  File \"c:\\Users\\ZY\\Desktop\\github_repos\\lohzhunyewcs\\deep-text-recognition-benchmark\\dataset.py\", line 6, in <module>\n",
      "    import lmdb\n",
      "ModuleNotFoundError: No module named 'lmdb'\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--train_data data_lmdb_release/training --valid_data data_lmdb_release/validation \\\n",
    "--select_data MJ-ST --batch_ratio 0.5-0.5 \\\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_boilerplate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
